{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnU0JkA1jYav"
      },
      "source": [
        "## LangChain Tool\n",
        "LangChain은 대형 언어 모델(LLM)을 사용하여 다양한 작업을 자동화하고 확장할 수 있도록 설계된 프레임워크로, 여러 도구(tool)들을 결합하여 효율적인 작업 흐름을 구축하는 데 중점을 둡니다. 이 프레임워크는 다양한 도구들과의 통합을 통해 LLM의 기능을 강화할 수 있으며, 복잡한 연산, 검색, API 호출 등을 수행할 때 사용됩니다.\n",
        "\n",
        "LangChain에서의 Tool 사용 방식은 주로 아래와 같은 흐름으로 이루어집니다.\n",
        "\n",
        "####1. LLM과 Tool의 결합\n",
        "LangChain에서는 LLM이 도구를 선택하고 이를 활용할 수 있도록 설계됩니다. LLM은 자체적인 답변 능력 외에도, 특정한 도구를 호출하여 더 복잡한 문제를 해결하거나 실시간 정보를 가져오도록 유도될 수 있습니다.\n",
        "예를 들어:\n",
        "- 검색 도구를 사용하여 실시간 정보를 가져오거나\n",
        "- 계산기 도구를 통해 수학적 계산을 수행하거나\n",
        "- API 호출을 통해 외부 시스템과 상호작용하는 등의 작업이 가능합니다.\n",
        "####2. Tool의 정의\n",
        "각 도구는 명시적인 기능을 가지고 있으며, LangChain에서는 이 도구들의 사용 방식을 미리 정의합니다. 도구는 함수처럼 정의될 수 있으며, LLM은 해당 도구를 사용할지 여부를 결정합니다.\n",
        "\n",
        "예를 들어, Python 코드를 실행하는 도구가 있다면, LLM은 복잡한 수식을 해결해야 할 때 해당 도구를 호출하도록 설정될 수 있습니다.\n",
        "\n",
        "####3. Tool 사용의 예\n",
        "- 검색(Search): 실시간 정보가 필요한 질문이 들어왔을 때, LLM은 사용자의 질문을 기반으로 검색 도구를 호출하여 최신 정보를 제공합니다.\n",
        "- 계산기(Calculator): 수학적 계산이나 데이터 분석이 필요할 경우 계산기 도구를 호출하여 결과를 반환합니다.\n",
        "- 데이터베이스 쿼리(Database Query): 데이터베이스에서 정보를 가져와야 할 경우, 쿼리 도구를 호출하여 데이터를 가져올 수 있습니다.\n",
        "\n",
        "####4. LangChain에서의 Tool 사용 시나리오\n",
        "- 질문에 대한 실시간 정보 제공: LLM이 특정 정보에 대해 답변할 때, 내부 지식만으로는 부족한 경우 외부 검색 도구를 사용하여 최신 정보를 검색하고 그 결과를 기반으로 답변을 생성합니다.\n",
        "- 복잡한 연산 처리: LLM이 간단한 계산을 넘어서 복잡한 수식이나 데이터 분석을 수행해야 할 경우, Python이나 계산기 도구를 사용해 연산을 수행하고 그 결과를 반환합니다.\n",
        "- API 통합: 외부 API와의 통합을 통해 실시간 데이터 수집, 외부 서비스와의 상호작용 등을 수행합니다.\n",
        "\n",
        "####5. Tool 사용의 장점\n",
        "LangChain의 도구 사용은 LLM이 가진 고유 능력 외에도 복잡한 작업을 처리할 수 있게 해줍니다. 이를 통해 더 높은 정확성과 유연성을 제공하며, 실시간 데이터와 연산, API 통합 등의 기능을 효과적으로 활용할 수 있습니다.\n",
        "\n",
        "####6. 에이전트(Agent)와 Tool의 결합\n",
        "LangChain의 **에이전트(Agent)**는 도구를 어떻게 사용할지 자동으로 결정하는 역할을 합니다. 즉, 에이전트는 사용자의 요구에 맞춰 여러 도구를 결합하여 작업을 처리하는 전략을 자동으로 세우고 실행합니다.\n",
        "\n",
        "결론적으로, LangChain에서의 Tool 사용은 LLM이 단순한 질문 응답을 넘어 실질적인 문제 해결과 작업 수행을 가능하게 하는 중요한 역할을 하며, 다양한 도구를 통합해 더 높은 수준의 작업을 수행하도록 돕습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVM4hi1IihZe",
        "outputId": "1ebfa068-80e5-4cac-c9f2-7442a9f9a2d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.5/362.5 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m391.5/391.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdDuHtjloN1j",
        "outputId": "8d8997ef-3b87-4bd0-941d-ce5e8aedda62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/52.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet langchain langchain-openai langchainhub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diSBkltMmKc3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from uuid import uuid4\n",
        "\n",
        "# unique_id를 uuid4()로 생성\n",
        "unique_id = str(uuid4())\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"LangChain Tool Use Quickstart - {unique_id}\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3mkLDmyaoAUY",
        "outputId": "d63ecda0-201b-40e2-e076-098962f4dac4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'9b4b0efa-6161-490c-80bf-3bc1afdc55a5'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dywP09yDo_Q_"
      },
      "outputs": [],
      "source": [
        "from langchain_core.tools import tool\n",
        "# tool 데코레이터는 함수를 특정 도구로 등록해주는 역할\n",
        "@tool\n",
        "def multiply(first_int: int, second_int: int) -> int: # 이 함수가 정수를 반환한다는 것을 명시\n",
        "    \"\"\"Multiply two integers together\"\"\"\n",
        "    return first_int * second_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gccX8aNjpmNl",
        "outputId": "4576531c-224e-43c8-bac7-0986b591dd8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "multiply\n",
            "Multiply two integers together\n",
            "{'first_int': {'title': 'First Int', 'type': 'integer'}, 'second_int': {'title': 'Second Int', 'type': 'integer'}}\n"
          ]
        }
      ],
      "source": [
        "print(multiply.name)\n",
        "print(multiply.description)\n",
        "print(multiply.args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCYx_ZpkpngZ",
        "outputId": "6eb21a67-1def-445b-a22f-a8208f48cc72"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multiply.invoke({\"first_int\":4,\"second_int\":5})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mED4rIjMqSOU"
      },
      "source": [
        "### Tool/function calling\n",
        "\n",
        "LLM에서 도구를 사용하는 가장 신뢰할 수 있는 방법 중 하나는 도구 호출 API(때로는 함수 호출이라고도 함)를 사용하는 것입니다. 이는 도구 호출을 명시적으로 지원하는 모델에서만 작동합니다.\n",
        "\n",
        "- 도구 호출을 지원하는 모델을  https://python.langchain.com/v0.1/docs/integrations/chat/ 에서 확인할 수 있으며,\n",
        "- https://python.langchain.com/v0.1/docs/modules/model_io/chat/function_calling/ 에서 도구 호출을 사용하는 방법에 대해 자세히 알아볼 수 있습니다 .\n",
        "\n",
        "먼저 모델과 도구를 정의하겠습니다. multiply 단일 도구로 시작하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFYftkmMqS7b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PAssuVHq8Zm"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "lim = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vVaCuMGq8Ta"
      },
      "outputs": [],
      "source": [
        "lim_with_tools = lim.bind_tools([multiply])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOEmsL5vrUZl",
        "outputId": "5f0d8c60-7ce9-44be-e622-dab706a1857c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'name': 'multiply',\n",
              "  'args': {'first_int': 5, 'second_int': 42},\n",
              "  'id': 'call_IhoR5yebaPl0m2OIWJWXZC5P',\n",
              "  'type': 'tool_call'}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "msg = lim_with_tools.invoke(\"whats 5 times forty tow\")\n",
        "msg.tool_calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viy5b9k_r1r1"
      },
      "source": [
        "좋습니다! 도구 호출을 생성할 수 있습니다. 하지만 실제로 도구를 호출하고 싶다면 어떨까요? 그렇게 하려면 생성된 도구 인수를 도구에 전달해야 합니다. 간단한 예로 첫 번째 tool_call의 인수를 추출해 보겠습니다.\n",
        "- llm_with_tools: 자연어 입력을 처리하여 도구 호출을 결정합니다.\n",
        "- 익명 함수는 LLM의 도구 호출 결과에서 인자를 가져옵니다.\n",
        "- 곱셈 함수가 해당 인자(4와 23)를 사용하여 곱셈 연산을 수행합니다.\n",
        "- 이 모든 단계가 체인으로 연결되어 있어, \"What's four times 23\" 같은 질문에 대해 최종적으로 92라는 결과가 도출됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J0dr3eGr2RF",
        "outputId": "2a604a0d-5b2e-4b2d-ab78-9a3e745bb7ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "92"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import iadd\n",
        "chain = lim_with_tools | (lambda x: x.tool_calls[0][\"args\"]) | multiply\n",
        "chain.invoke(\"Whats four times 23\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXpwsBv5vfbr"
      },
      "source": [
        "- llm_with_tools: 질문이 \"4 곱하기 23은 무엇인가요?\"와 같은 수학 문제일 때, 이 언어 모델은 자연어를 분석하고 그 결과를 도구로 전달\n",
        "- | (lambda x: x.tool_calls[0][\"args\"]): \"4 곱하기 23\"이라는 질문을 처리한 결과로 도구 호출이 발생하면, 이 호출에서 인수 정보(예: {\"first_int\": 4, \"second_int\": 23})를 가져오는 역할\n",
        "- | multiply: 전달된 인수가 {first_int: 4, second_int: 23}이라면, 이 도구는 4와 23을 곱해서 92라는 결과를 반환\n",
        "- chain.invoke(\"What's four times 23\"): 체인 전체를 실행하는 역할"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPlZlufnwZ7i"
      },
      "source": [
        "### Agents\n",
        "\n",
        "체인은 사용자 입력에 필요한 특정 도구 사용 순서를 알고 있을 때 유용합니다. 하지만 특정 사용 사례의 경우 도구를 사용하는 횟수는 입력에 따라 달라집니다. 이런 경우 모델 자체가 도구를 사용할 횟수와 순서를 결정하도록 합니다. 에이전트는 우리가 바로 이를 할 수 있도록 합니다.\n",
        "\n",
        "LangChain에는 다양한 사용 사례에 최적화된 여러 내장 에이전트가 제공됩니다. 여기에서 모든 에이전트 유형 에 대해 읽어보세요 .\n",
        "\n",
        "우리는 일반적으로 가장 신뢰할 수 있고 대부분의 사용 사례에 권장되는 도구인 호출 에이전트를 사용할 것입니다 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucgZwkrqvver"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "from langchain.agents import AgentExecutor, create_tool_calling_agent, tool\n",
        "from langchain.agents import AgentType"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3USJ7iAw5m6"
      },
      "source": [
        "### LangChain Hub: 커뮤니티 허브에서 프롬프트 탐색 및 기여\n",
        "LangChain Hub는 LangChain 프레임워크를 사용하는 개발자와 사용자들을 위한 중앙화된 플랫폼입니다. 이 허브는 프롬프트, 체인, 에이전트와 같은 다양한 리소스를 커뮤니티가 공유하고 기여할 수 있도록 지원하는 커뮤니티 주도의 저장소입니다. 대형 언어 모델(LLM)을 활용하여 복잡한 애플리케이션을 개발할 때 필요한 여러 요소들을 제공하며, 이를 통해 LangChain 허브는 고품질의 리소스를 탐색하고 프로젝트에 통합할 수 있는 중앙 허브 역할을 합니다.\n",
        "\n",
        "https://smith.langchain.com/hub?organizationId=9707e039-d288-5654-b8cc-7926348c3a05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_f9ltYwNw6qI",
        "outputId": "8eaab4d6-7664-4285-931e-6558bd11f845"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================\u001b[1m System Message \u001b[0m================================\n",
            "\n",
            "You are a helpful assistant\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{chat_history}\u001b[0m\n",
            "\n",
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{input}\u001b[0m\n",
            "\n",
            "=============================\u001b[1m Messages Placeholder \u001b[0m=============================\n",
            "\n",
            "\u001b[33;1m\u001b[1;3m{agent_scratchpad}\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Get the pormpt to use - can be replaced with anu prompt that includes variables \"agent_scratchpad\" and \"input\"\n",
        "prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
        "prompt.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZqEWVHqyy9L"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def add(first_int: int, second_int: int) -> int:\n",
        "    \"\"\"Add two integers together\"\"\"\n",
        "    return first_int + second_int\n",
        "\n",
        "@tool\n",
        "def exponentiate(base: int, exponent: int) -> int:\n",
        "    \"\"\"Raise a number to a power\"\"\"\n",
        "    return base ** exponent\n",
        "\n",
        "tools = [multiply, add, exponentiate]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s35irIzMzA4K"
      },
      "outputs": [],
      "source": [
        "# Construct the tool calling agent\n",
        "agent = create_tool_calling_agent(lim, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKmG1wL1z8g-"
      },
      "outputs": [],
      "source": [
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YyeB0m3s0DAX",
        "outputId": "96f121bd-ced1-4ecc-86be-5a67c06c0bc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3, 'exponent': 5}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m243\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `add` with `{'first_int': 12, 'second_int': 3}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[33;1m\u001b[1;3m15\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `multiply` with `{'first_int': 243, 'second_int': 15}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3m3645\u001b[0m\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `exponentiate` with `{'base': 3645, 'exponent': 2}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[38;5;200m\u001b[1;3m13286025\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( (3^5 \\times (12 + 3))^2 \\) is \\( 13,286,025 \\).\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'input': 'Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result',\n",
              " 'output': 'The result of \\\\( (3^5 \\\\times (12 + 3))^2 \\\\) is \\\\( 13,286,025 \\\\).'}"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "agent_executor.invoke(\n",
        "    {\n",
        "        \"input\":\"Take 3 to the fifth power and multiply that by the sum of twelve and three, then square the whole result\"\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URqg-h5J1q7l"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.agents import"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
