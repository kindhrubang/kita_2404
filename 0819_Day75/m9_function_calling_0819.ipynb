{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOx_1SZ4Armf"
      },
      "source": [
        "#### Function Calling의 사용\n",
        "- 이 코드에서 function calling은 모델이 적절한 시점에 외부 함수(get_current_weather)를 호출하도록 유도합니다. 모델이 What is the current weather in {user_location}?와 같은 질문에 응답할 때, 해당 함수가 정의되어 있으면 모델은 그 함수를 호출하여 날씨 정보를 가져오려 합니다.\n",
        "\n",
        "- function_call=\"auto\" 설정을 통해 GPT 모델은 적절한 함수가 있을 때 자동으로 그 함수를 호출할 수 있습니다. 여기서는 get_current_weather 함수 명세를 통해 사용자가 입력한 위치에 맞는 날씨 정보를 가져올 수 있도록 유도됩니다.\n",
        "\n",
        "- 만약 모델이 함수 호출을 결정하면, 응답에 function_call이 포함되며, 이때 함수 이름과 그 인자가 함께 반환됩니다. 그런 후에 함수가 호출되고, 결과가 다시 모델에 제공됩니다.\n",
        "\n",
        "이 과정에서 모델은 단순히 인자를 생성하고, 함수를 호출하는 것은 개발자의 책임입니다. OpenAI의 API는 실제 함수 실행을 수행하지 않으므로, 함수 호출 후 결과를 처리하고 다시 모델에 넘기는 과정을 수동으로 처리하게 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "54AS7vJU_sTz"
      },
      "outputs": [],
      "source": [
        "!pip install openai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I8gfWToB_Fj"
      },
      "source": [
        "openweather 사이트 api로 연결하여 혅날씨를 조회할 수 있는 챗봇\n",
        "\n",
        "https://home.openweathermap.org/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxXWsa0FTIwI",
        "outputId": "14db4e55-cdb8-49e9-de79-f1d0308ffecb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"Seoul, Korea\"}', name='get_current_weather'), tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "\n",
        "#OpenAI AI 키 설정\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "#날씨 API 키 설정 (예: openweathermap)\n",
        "weather_api_key  = '4'\n",
        "\n",
        "# 날씨 정보를 가져오는 함수 정의\n",
        "def get_current_weather(location):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={weather_api_key}&units=metric\"\n",
        "    response = requests.get(url)\n",
        "    return response.json()\n",
        "\n",
        "# 사용자 요청 메시지\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"What is the weather in Seoul, Korea?\"}\n",
        "]\n",
        "\n",
        "# GPT-4 모델 호출\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini-2024-07-18',\n",
        "    messages = messages,\n",
        "    functions = [{\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather for a specific location\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"The name of the city to get the weather for\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        }\n",
        "    }],\n",
        "    function_call=\"auto\"\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력합니다\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "print(response_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWqCGAz0Hj8Y",
        "outputId": "ec5627b0-1f4a-40e6-d012-9915ab5591f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current weather in Seoul, Korea is clear with a temperature of 35.66°C. The temperature feels like 40.25°C due to humidity and other factors. Here are some additional details:\n",
            "\n",
            "- **Condition:** Clear sky\n",
            "- **Humidity:** 45%\n",
            "- **Wind Speed:** 1.53 m/s coming from the southwest (201°)\n",
            "- **Visibility:** 10 km\n",
            "- **Cloud Cover:** 9%\n",
            "\n",
            "It's a hot day, so stay hydrated if you're out!\n"
          ]
        }
      ],
      "source": [
        "# 도구 호출 여부 확인\n",
        "function_call = response_message.function_call\n",
        "if function_call:\n",
        "    tool_function_name = function_call.name\n",
        "    tool_arguments = json.loads(function_call.arguments)\n",
        "    # 함수 호출 및 결과 처리\n",
        "    if tool_function_name == \"get_current_weather\":\n",
        "        location = tool_arguments[\"location\"]\n",
        "        weather_result = get_current_weather(location)\n",
        "\n",
        "        # 함수 호출 결과 메시지 추가\n",
        "        messages.append({\n",
        "            \"role\": \"function\",\n",
        "            \"name\": tool_function_name,\n",
        "            \"content\": json.dumps(weather_result)\n",
        "        })\n",
        "\n",
        "        #모델 재호출\n",
        "        model_response_with_function_call = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini-2024-07-18',\n",
        "            messages = messages,\n",
        "        )\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "    else:\n",
        "        print(f\"Error: function {tool_function_name} does not exist\")\n",
        "else:\n",
        "    print(response.message.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kI16Oah7Qfmi"
      },
      "source": [
        "전체 코드\n",
        "*    location 입력 받아서 응답"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LtlUhwcQk1k",
        "outputId": "490ab218-6e2b-4e4b-8676-739b0e15526b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the location to get the current weather: tokyo\n",
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=FunctionCall(arguments='{\"location\":\"tokyo\"}', name='get_current_weather'), tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "\n",
        "#OpenAI AI 키 설정\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "#날씨 API 키 설정 (예: openweathermap)\n",
        "weather_api_key  = '23d2f'\n",
        "\n",
        "# 날씨 정보를 가져오는 함수 정의\n",
        "def get_current_weather(location):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={weather_api_key}&units=metric\"\n",
        "    response = requests.get(url)\n",
        "    return response.json\n",
        "\n",
        "# 사용자 요청 메시지\n",
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Please provide the location to get the current weather information\"}\n",
        "]\n",
        "\n",
        "\n",
        "# 사용자 입력 받기\n",
        "user_location = input(\"Enter the location to get the current weather: \")\n",
        "messages.append({\"role\": \"user\", \"content\": f\"What is the weather in {user_location}\"})\n",
        "\n",
        "# GPT-4 모델 호출\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini-2024-07-18',\n",
        "    messages = messages,\n",
        "    functions = [{\n",
        "        \"name\": \"get_current_weather\",\n",
        "        \"description\": \"Get the current weather for a specific location\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": f\"The name of the city to get the weather for target is {user_location}\",\n",
        "                },\n",
        "            },\n",
        "            \"required\": [\"location\"],\n",
        "        }\n",
        "    }],\n",
        "    function_call=\"auto\"\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력합니다\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "print(response_message)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkUmXhQOBfZ2",
        "outputId": "8dc8bf90-1230-4637-affd-292c77b2fa47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'location': 'Seoul, Korea'}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tool_arguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "I9c53tO0Ryb6",
        "outputId": "897357ad-3f53-4643-f948-5fed3d1d783f"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Object of type method is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-daa59df8a7a8>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"function\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtool_function_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweather_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         })\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type method is not JSON serializable"
          ]
        }
      ],
      "source": [
        "# 도구 호출 여부 확인\n",
        "function_call = response_message.function_call\n",
        "if function_call:\n",
        "    tool_function_name = function_call.name\n",
        "    tool_arguments = json.loads(function_call.arguments)\n",
        "    # 함수 호출 및 결과 처리\n",
        "    if tool_function_name == \"get_current_weather\":\n",
        "        location = tool_arguments[\"location\"]\n",
        "        weather_result = get_current_weather(location)\n",
        "\n",
        "        # 함수 호출 결과 메시지 추가\n",
        "        messages.append({\n",
        "            \"role\": \"function\",\n",
        "            \"name\": tool_function_name,\n",
        "            \"content\": json.dumps(weather_result)\n",
        "        })\n",
        "\n",
        "        #모델 재호출\n",
        "        model_response_with_function_call = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini-2024-07-18',\n",
        "            messages = messages,\n",
        "        )\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "    else:\n",
        "        print(f\"Error: function {tool_function_name} does not exist\")\n",
        "else:\n",
        "    print(response.message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "_JKjNsF8BoDT",
        "outputId": "9d83bce9-9220-499a-84f1-912c2b90b37a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>requests.models.Response.json</b><br/>def json(**kwargs)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/requests/models.py</a>Returns the json-encoded content of a response, if any.\n",
              "\n",
              ":param \\*\\*kwargs: Optional arguments that ``json.loads`` takes.\n",
              ":raises requests.exceptions.JSONDecodeError: If the response body does not\n",
              "    contain valid json.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 947);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ],
            "text/plain": [
              "<bound method Response.json of <Response [200]>>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_current_weather(\"Seoul\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "HWXSS0NSBzFY",
        "outputId": "6b00d370-6dd1-49a8-9784-e78f9d173673"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Object of type method is not JSON serializable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-74ec46334eec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_current_weather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Seoul\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
            "\u001b[0;32m/usr/lib/python3.10/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Object of type method is not JSON serializable"
          ]
        }
      ],
      "source": [
        "json.dumps(get_current_weather(\"Seoul\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Kn2MHRvYCsE"
      },
      "source": [
        "## How to call functions with model generated arguments\n",
        "\n",
        "다음 예제에서는 모델에서 생성된 입력을 갖는 함수를 실행하는 방법을 보여주고 이를 사용하여 데이터베이스에 대한 질문에 답할 수 있는 에이전트를 구현합니다. 단순화를 위해 Chinook 샘플 데이터베이스를 사용하겠습니다 .\n",
        "\n",
        "참고: 모델이 올바른 SQL을 생성하는 데 완벽하게 신뢰할 수 없기 때문에 프로덕션 환경에서 SQL 생성은 위험할 수 있습니다.\n",
        "\n",
        "이 코드는 OpenAI의 GPT 모델을 사용하여 SQLite 데이터베이스에서 음악 관련 질문에 대한 답변을 SQL 쿼리로 변환한 후, 해당 쿼리를 실행하여 결과를 반환하는 방식으로 function calling을 구현한 예시입니다. 여기서는 사용자가 앨범 관련 질문을 하면, GPT-4가 질문을 SQL 쿼리로 변환하고, SQLite 데이터베이스를 조회하여 결과를 반환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nyEGAy_NYDIz",
        "outputId": "e1f7d0fc-701e-4490-9a5e-de5e43e17170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Opened database successfully\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "# sqlite3.connect()를 통해 Google Drive에 있는 Chinook.db  SQLite 데이터 베이스에 연결\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/kdt_240424/m9_LLM/data/Chinook.db\")\n",
        "print(\"Opened database successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aT5UB1GeZCKn"
      },
      "source": [
        "데이터베이스 테이블 및 열 정보 조회\n",
        "*    get_table_names, get_column_name함수를 통해 데이터베이스의 테이블 및 열 이름을 가져옵니다\n",
        "*    이 정보는 나중에 GPT 모델이 SQL 쿼리를 생성할 때 사용할 스키마 정보를 제공하는데 활용됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "eWz2j6CabPUu"
      },
      "outputs": [],
      "source": [
        "# 데이터베이스에서 테이블 목록을 추출하는 함수입니다 sqlite.master 테이블에서 \"type\"이 'table'인 항목들의 이름을 ㅏㄱ져오\n",
        "def get_table_names(conn):\n",
        "    \"\"\"Return a list of table names.\"\"\"\n",
        "    table_names = []\n",
        "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    for table in tables.fetchall():\n",
        "        table_names.append(table[0])\n",
        "    return table_names\n",
        "\n",
        "#PRAGMA table_info(table_name) 명령을 사용하여 테이블의 스키마 정보를 가져요고, 컬럼 이름을 리스트로 변환\n",
        "def get_column_names(conn, table_name):\n",
        "    \"\"\"Return a list of column names.\"\"\"\n",
        "    column_names = []\n",
        "    columns = conn.execute(f\"PRAGMA table_info({table_name});\").fetchall()\n",
        "    for col in columns:\n",
        "        column_names.append(col[1])\n",
        "    return column_names\n",
        "\n",
        "def get_database_info(conn):\n",
        "    \"\"\"Return a list of dicts containing the table name and columns for each table in the database.\"\"\"\n",
        "    table_dicts = []\n",
        "    for table_name in get_table_names(conn):\n",
        "        columns_names = get_column_names(conn, table_name)\n",
        "    return table_dicts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2YG9J5mcOdI"
      },
      "source": [
        "데이터베이스의 테이블과 열 정보를 문자열 형태로 저장하여, 나중에 SQL 쿼리 장성시 참조할 수 있도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "1ZcEiFLAcoq-"
      },
      "outputs": [],
      "source": [
        "database_schema_dict = get_database_info(conn)\n",
        "database_schema_string  = '\\n'.join(\n",
        "    [\n",
        "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
        "        for table in database_schema_dict\n",
        "    ]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TWGxp85eXlz"
      },
      "source": [
        "tools라는 리스트에 ask_database라는 함수 명세를 정의합니다.\n",
        "- 이 함수는 사용자의 질문에 맞는 SQL 쿼리를 받아 데이터베이스에서 정보를 조회하고, 이를 반환하는 기능을 합니다.\n",
        "- 함수의 매개변수로 query가 있으며, 이는 SQL 쿼리를 텍스트 형태로 전달받아 실행하는 구조입니다.\n",
        "- 중요한 점은 database_schema_string이 함수 설명에 포함되어 있어, 모델이 데이터베이스 스키마에 맞는 SQL 쿼리를 생성할 수 있도록 도움을 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "fBhOeytie74E"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    {\n",
        "        \"type\": \"function\",\n",
        "        \"function\":{\n",
        "            \"name\": \"ask_database\",\n",
        "            \"description\": \"Use this function to answer user questions about music. Output should be a fully formed SQL query.\",\n",
        "            \"parameters\": {\n",
        "                \"type\": \"object\",\n",
        "                \"properties\": {\n",
        "                    \"query\": {\n",
        "                        \"type\": \"object\",\n",
        "                        \"description\": f\"\"\"\n",
        "                        SQL query extracting info to answer the user's question\n",
        "                        SQL, should be written using this database schema:\n",
        "                        {database_schema_string}\n",
        "                        The query should be returned in plain text, not in JSON.\n",
        "                        \"\"\",\n",
        "                    }\n",
        "                },\n",
        "                \"required\": [\"query\"],\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD2VPLKngbv9"
      },
      "source": [
        "## Executing SQL queries\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NI2DK5JvfUSq"
      },
      "outputs": [],
      "source": [
        "def ask_database(conn, query):\n",
        "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
        "    try:\n",
        "        results = str(conn.execute(query).fetchall())\n",
        "    except Exception as e:\n",
        "        results = f\"query failed with error: {e}\"\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H4ssNXxNhKDd"
      },
      "source": [
        "##### Steps to invoke a function call using Chat Completions API:\n",
        "\n",
        "- 1단계 : 모델이 사용할 도구를 선택하도록 하는 내용으로 모델을 프롬프트합니다. 함수 이름 및 서명과 같은 도구에 대한 설명은 '도구' 목록에 정의되어 API 호출에서 모델에 전달됩니다. 선택한 경우 함수 이름과 매개변수가 응답에 포함됩니다.\n",
        "- 2단계 : 모델이 함수를 호출하려고 하는지 프로그래밍적으로 확인합니다. 참이면 3단계로 진행합니다.\n",
        "- 3단계 : 응답에서 함수 이름과 매개변수를 추출하고 매개변수와 함께 함수를 호출합니다. 결과를 메시지에 추가합니다.\n",
        "- 4단계 : 메시지 목록으로 채팅 완료 API를 호출하여 응답을 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0cAvtwhhKpb",
        "outputId": "2a5ab306-b4f7-4860-a622-f2908b56c6cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionMessage(content=None, refusal=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9iOj7ZJOeK8C2aIiEYk4cXLE', function=Function(arguments='{}', name='ask_database'), type='function')])\n"
          ]
        }
      ],
      "source": [
        "# 사용자의 요청 메시지를 정의 합니다.\n",
        "messages = [{\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"What is the name of the album with the most tracks?\"\n",
        "}]\n",
        "\n",
        "# 사용자의 질문에 대한 응답을 생성 tools와 tool_choice 파라미터는 모델이 데이터베이스 쿼리를 인식하고 자동으로 도구를 선택할 수 있도록 돕습니다.\n",
        "response = client.chat.completions.create(\n",
        "    model = 'gpt-4o-mini-2024-07-18',\n",
        "    messages = messages,\n",
        "    tools = tools,\n",
        "    tool_choice = 'auto'\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지를 messages 리스트에 추가하고 출력합니다\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "\n",
        "print(response_message)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "yo5UeloIiFDS",
        "outputId": "09a3fedb-c98f-4061-ef08-779e5f71d4d8"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'query'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-d919f81cc8c0>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtool_call_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtool_function_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtool_query_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtool_calls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"query\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 도구 호출 함수 이름이 'ask_database'인 경우 'ask_database 함수를 호출하여 데이터베이스 쿼리를 실행하고 결과를 messages 리스트에 추가 합니다\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'query'"
          ]
        }
      ],
      "source": [
        "# 모델 응답에서 도구 호출이 포함되어 있는지 확인하고, 도구 호출이 있다면 도구 호출 10, 함수 이름 및 쿼리 문자열을 추출한다\n",
        "tool_calls = response_message.tool_calls\n",
        "if tool_calls:\n",
        "\n",
        "    # if true the model will return the name of the tool / function to call and the argument(s)\n",
        "    tool_call_id = tool_calls[0].id\n",
        "    tool_function_name = tool_calls[0].function.name\n",
        "    tool_query_string = json.loads(tool_calls[0].function.arguments)[\"query\"]\n",
        "\n",
        "    # 도구 호출 함수 이름이 'ask_database'인 경우 'ask_database 함수를 호출하여 데이터베이스 쿼리를 실행하고 결과를 messages 리스트에 추가 합니다\n",
        "    if tool_function_name == \"ask_database\":\n",
        "        results  = ask_database(conn, tool_query_string)\n",
        "\n",
        "        messages.append({\n",
        "            \"role\":\"tool\",\n",
        "            \"tool_call_id\":tool_call_id,\n",
        "            \"name\":tool_function_name,\n",
        "            \"content\":results\n",
        "        })\n",
        "        #도구 호출 결과가 포함된 messages 리스트를 사용하여 모델을 다수 호출하고 최종 응답을 출력합니다\n",
        "        #Note that messages with role 'tool' most be a response to a preceding messages with 'tool_calls\n",
        "        model_response_with_tool_calls = client.chat.completions.create(\n",
        "            model = 'gpt-4o-mini-2024-07-18',\n",
        "            messages = messages,\n",
        "        ) #  get a new respoonse from the model where it can see the function response\n",
        "        print(model_response_with_function_call.choices[0].message.content)\n",
        "        # 도구 호출 함수 이름이 \"ask_database\"가 아닌 경우 오류메시지를 출력하거나 도구호출이 없으면 모델의 응답내용을 바로 출력합니다\n",
        "\n",
        "    else:\n",
        "        print(f\"Error: function {tool_function_name} does not exist\")\n",
        "else:\n",
        "    print(response.message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cSuwczmJO-fb",
        "outputId": "5a22c22b-24b2-4353-cb57-b1f1cd3dd2eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Opened database successfully\n",
            "The album with the most tracks is titled \"Greatest Hits.\"\n"
          ]
        }
      ],
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import openai\n",
        "import sqlite3\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# OpenAI API 키 설정\n",
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=\"\")\n",
        "\n",
        "# 데이터베이스 연결\n",
        "conn = sqlite3.connect(\"/content/drive/MyDrive/kdt_240424/m9_LLM/data/Chinook.db\")\n",
        "print(\"Opened database successfully\")\n",
        "\n",
        "# 함수 정의\n",
        "def get_table_names(conn):\n",
        "    table_names = []\n",
        "    tables = conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
        "    for table in tables.fetchall():\n",
        "        table_names.append(table[0])\n",
        "    return table_names\n",
        "\n",
        "def get_column_names(conn, table_name):\n",
        "    column_names = []\n",
        "    columns = conn.execute(f\"PRAGMA table_info('{table_name}');\").fetchall()\n",
        "    for col in columns:\n",
        "        column_names.append(col[1])\n",
        "    return column_names\n",
        "\n",
        "def get_database_info(conn):\n",
        "    table_dicts = []\n",
        "    for table_name in get_table_names(conn):\n",
        "        columns_names = get_column_names(conn, table_name)\n",
        "        table_dicts.append({\"table_name\": table_name, \"column_names\": columns_names})\n",
        "    return table_dicts\n",
        "\n",
        "database_schema_dict = get_database_info(conn)\n",
        "database_schema_string = \"\\n\".join(\n",
        "    [\n",
        "        f\"Table: {table['table_name']}\\nColumns: {', '.join(table['column_names'])}\"\n",
        "        for table in database_schema_dict\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 함수 정의\n",
        "def ask_database(conn, query):\n",
        "    \"\"\"Function to query SQLite database with a provided SQL query.\"\"\"\n",
        "    try:\n",
        "        results = str(conn.execute(query).fetchall())\n",
        "    except Exception as e:\n",
        "        results = f\"query failed with error: {e}\"\n",
        "    return results\n",
        "\n",
        "# 사용자의 질문에 대한 응답을 생성하는 함수\n",
        "messages = [{\n",
        "    \"role\":\"user\",\n",
        "    \"content\": \"What is the name of the album with the most tracks?\"\n",
        "}]\n",
        "\n",
        "# 'functions' 정의\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"ask_database\",\n",
        "        \"description\": \"Use this function to answer user questions about music. Input should be a fully formed SQL query.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"query\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": f\"\"\"\n",
        "                        SQL query extracting info to answer the user's question.\n",
        "                        SQL should be written using this database schema:\n",
        "                        {database_schema_string}\n",
        "                        The query should be returned in plain text, not in JSON.\n",
        "                    \"\"\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"query\"]\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# 모델 응답 요청\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini-2024-07-18\",\n",
        "    messages=messages,\n",
        "    functions=functions,  # 'tools' 대신 'functions' 사용\n",
        "    function_call=\"auto\"  # 'tool_choice' 대신 'function_call' 사용\n",
        ")\n",
        "\n",
        "# 모델의 응답 메시지와 함수 호출 처리\n",
        "response_message = response.choices[0].message\n",
        "messages.append(response_message)\n",
        "\n",
        "\n",
        "# function_call이 있는지 확인\n",
        "if response_message.function_call:  # 'function_call' 속성을 직접 확인\n",
        "    # 함수 호출 정보 추출\n",
        "    function_name = response_message.function_call.name\n",
        "    function_arguments = json.loads(response_message.function_call.arguments)\n",
        "\n",
        "    # 'ask_database' 함수 호출\n",
        "    if function_name == 'ask_database':\n",
        "        query = function_arguments['query']\n",
        "        results = ask_database(conn, query)\n",
        "\n",
        "        messages.append({\n",
        "            \"role\": \"function\",\n",
        "            \"name\": function_name,\n",
        "            \"content\": results\n",
        "        })\n",
        "\n",
        "        # 모델의 최종 응답 요청\n",
        "        final_response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini-2024-07-18\",\n",
        "            messages=messages,\n",
        "        )\n",
        "\n",
        "        print(final_response.choices[0].message.content)\n",
        "else:\n",
        "    # 함수 호출이 없으면 결과 출력\n",
        "    print(response_message.content)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
